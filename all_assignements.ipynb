{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGIS \n",
    "Given: A positive integer n≤10000mfollowed by a permutation π of length n.\n",
    "Return: A longest increasing subsequence of π, followed by a longest decreasing subsequence of π.\n",
    "NOTES:\n",
    "longest increasing sequence: longest subset in permutations including only the elements that increase\n",
    "longest decreasing seqeuncesequence:longest subset in permutations including only the elements that decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 101 107 283 289 292 324 334 359 450 497 512 540 559 615 629 630 636 638 789 903 963 1003 1006 1030 1040 1049 1054 1116 1143 1234 1249 1299 1321 1348 1369 1386 1405 1432 1441 1535 1619 1641 1679 1708 1730 1755 1759 1836 1875 1927 1950 1973 2049 2054 2088 2089 2093 2214 2240 2339 2347 2403 2435 2468 2667 2680 2696 2765 2945 3001 3004 3161 3172 3222 3281 3358 3384 3450 3454 3499 3502 3505 3506 3528 3535 3593 3600 3612 3640 3798 3831 3941 4017 4022 4243 4380 4473 4495 4591 4598 4612 4706 4784 4816 4864 5030 5033 5058 5102 5255 5311 5360 5464 5469 5584 5645 5650 5663 5677 5724 5746 5749 5755 5785 5801 5824 5932 5942 5950 5965 6004 6046 6096 6223 6228 6234 6398 6420 6428 6472 6553 6664 6694 6700 6703 6768 6839 6853 6868 6988 7039 7054 7126 7147 7207 7234 7249 7344 7375 7394 7442 7485 7587 7683 7803 7924 7938 7954 7955 8107 8160\n",
      "7906 7880 7827 7809 7797 7792 7733 7622 7605 7588 7564 7432 7295 7258 7228 7180 7130 6939 6916 6914 6903 6874 6766 6733 6676 6588 6419 6407 6390 6383 6353 6340 6332 6310 6276 6272 6220 6103 6058 6052 6041 6006 5927 5831 5826 5764 5763 5691 5589 5530 5522 5506 5337 5258 5234 5181 5076 5021 4853 4767 4759 4696 4690 4659 4585 4575 4534 4482 4459 4437 4340 4321 4308 4271 4269 4234 4207 4194 4156 4122 4121 4118 4091 4070 4047 4044 3997 3976 3967 3904 3705 3641 3628 3624 3611 3540 3530 3481 3450 3429 3425 3406 3339 3330 3155 3153 2921 2832 2768 2729 2691 2598 2556 2553 2437 2431 2355 2322 2321 2235 2206 2014 2005 1935 1923 1900 1847 1786 1745 1717 1587 1514 1438 1396 1325 1312 1256 1252 1179 1157 1154 1100 1090 1087 1080 1068 934 905 886 825 728 720 706 693 691 657 617 614 587 568 551 534 514 476 470 466 443 420 407 327 316 210 83\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def longest_increasing_sequence(sequence):\n",
    "    n=len(sequence)\n",
    "    dp=[1]*n#initialize dp considered that each element is a subset array of length 1\n",
    "    parent=[-1]*n#the earray takes all elements in reverse order, starting from last element of the\n",
    "    #sequence and taking only those of the iteration\n",
    "    for i in range(1,n):\n",
    "        for j in range(i):\n",
    "            if sequence[i]>sequence[j] and dp[i]<dp[j]+1:#extending only valid increasing sequence and \n",
    "                #update dp to include element at last position, so the element j bigger than i, so we update\n",
    "                dp[i]=dp[j]+1\n",
    "                parent[i]=j\n",
    "            #find length of lis and its last element\n",
    "    fin_len=max(dp)\n",
    "    fin_ind=dp.index(fin_len)\n",
    "    #lis\n",
    "    lis=[]\n",
    "    while fin_ind != -1:#we are checking in reverse\n",
    "       #get current element and add to lis subsequence\n",
    "        lis.append(sequence[fin_ind])\n",
    "        fin_ind=parent[fin_ind]#restart with previous element\n",
    "    lis.reverse()\n",
    "    return lis\n",
    "#lis=longest_increasing_sequence(sequence=)\n",
    "def longest_decreasing_sequence(sequence):\n",
    "    n=len(sequence)\n",
    "    dp=[1]*n#initialize dp considered that each element is a subset array of length 1\n",
    "    parent=[-1]*n#the earray takes all elements in reverse order, starting from last element of the\n",
    "    #sequence and taking only those of the iteration\n",
    "    for i in range(1,n):\n",
    "        for j in range(i):\n",
    "            if sequence[i]<sequence[j] and dp[i]<dp[j]+1:#extending only valid decreasing sequence and \n",
    "                #update dp to include element at last position, so the element j bigger than i, so we update\n",
    "                dp[i]=dp[j]+1\n",
    "                parent[i]=j\n",
    "            #find length of lis and its last element\n",
    "    fin_len=max(dp)\n",
    "    fin_ind=dp.index(fin_len)\n",
    "    #lis\n",
    "    lds=[]\n",
    "    while fin_ind != -1:#we are checking in reverse\n",
    "#get current element and add to lis subsequence\n",
    "        lds.append(sequence[fin_ind])\n",
    "        fin_ind=parent[fin_ind]#restart with previous element\n",
    "    lds.reverse()\n",
    "    return lds\n",
    "def main_funct():\n",
    "    #read input from a file\n",
    "    with open (\"lgis.txt\", \"r\") as file:\n",
    "        lines=file.readlines()\n",
    "\n",
    "    n=int(lines[0].strip())#first line is length of permutation\n",
    "    π=lines[1].strip()#second line is the permutation\n",
    "    permutation=list(map(int,π.split()))#convert space seprataed numbers into list of integers\n",
    "    lis=longest_increasing_sequence(permutation)\n",
    "    lds=longest_decreasing_sequence(permutation)\n",
    "    print(' '.join(map(str, lis)))\n",
    "    print(' '.join(map(str, lds)))\n",
    "if __name__ == '__main__':\n",
    "    main_funct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEEQ\n",
    "Given: Two DNA strings s and t (each of length at most 1 kbp) in FASTA format.\n",
    "Return: One collection of indices of s in which the symbols of t appear as a subsequence of s. \n",
    "If multiple solutions exist, you may return any one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 5 7 20 21 24 27 29 37 41 45 47 50 57 64 66 67 75 78 81 84 87 99 111 113 117 129 132 133 139 145 148 151 155 159 163 168 175 183 198 200 204 213 217 218 220 224 232 235 236 239 243 247 249 257 267 270 289 296 297 304 308 309 310 312 314 317 318 326 328 332 336 340 341 362 363 371 377 378 386 387 389 391 399 400 401 402 405 406 418 419 435 437 442 444 457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#biopython to read fasta files\n",
    "from Bio import SeqIO\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta\n",
    "        sequences.append(str(record.seq))\n",
    "    return sequences\n",
    "\n",
    "def subseq_indices(s,t):\n",
    "    indices=[]#store indices\n",
    "    s_index=0\n",
    "    for char in t:#iterate in t to find matching subsequences\n",
    "        while s_index<len(s)and s[s_index] != char:#find occurrence in s-index\n",
    "            s_index+=1#if char found, record the index\n",
    "        if s_index<len(s):\n",
    "            indices.append(s_index+1)#comvert to 1-based index\n",
    "            s_index +=1#move in s\n",
    "        else:\n",
    "            break#exit if char not found\n",
    "    return indices\n",
    "#main function that reads input and solves problem\n",
    "def main():\n",
    "    sequences=read_fasta(\"sseq.fasta\")\n",
    "    s=sequences[0]#first sequence\n",
    "    t=sequences[1]#second sequence\n",
    "    indices=subseq_indices(s,t)#indices where t is a subsequence of s\n",
    "    print(\" \".join(map(str, indices)))\n",
    "\n",
    "#run\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCSQ\n",
    "Given: Two DNA strings s and t (each having length at most 1 kbp) in FASTA format.\n",
    "Return: A longest common subsequence of s and t. (If more than one solution exists, you may return any one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCTGAGCCGATAGACTGGACAATAAACGATTTGTGTTTCGGGGGGGCTATGGCCATGGGATTAACTAGCAGCTTAAGGGTGTGAGGTAAAAATTCATGAGTTGAGCGCCCCTAAACAGCATGTCGTTTGGAGTATCGCGGCTTCCCGGATTATTATATTCATGTGAAGAGTATTCAGTTCTTAGCCACAGGCGGAGTAACGATCTTTCTTCGCTTAGGGGGTCCATGTTTAGGACGATGGTTACCGACGACGGTTCCTGGCACTTTGAGAGGTAATAGCTGTTCTGCGAGAATTTCCCTCAACTTGATTAAGCCAGGGACTTACTCTCGCGCATACGCAGCAACACCGGGGCGTGCATATAATTGGAAAGCACAATTGGGGGGCATCTGTCCATGTCCCTGGTACAGATGACGACTAGGGTATTTAAATTGGCTCTCCCCATGGATTATAAACTTTATTGGCACGGTCACCCATTTGGGGAGGTTGGCGGGTGCCAACTCCCTTCTGTGCTAGAGACCCAAAGTTCGACATTTCTCTAAAGCGTAATGTTTGGCAGTTACTGGTACAGTGCTATTTAACATGCGTCTCC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta using biopython function(record refers to header and seq)\n",
    "        sequences.append(str(record.seq))#add sequences of dna to empty list\n",
    "    return sequences#return list of dna sequences\n",
    "\n",
    "def longest_common_subseq(s,t):\n",
    "    m,n=len(s), len(t)\n",
    "    dp=[[0]*(n+1) for _ in range(m+1)]#initialize dp\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if s[i-1]==t[j-1]:\n",
    "                dp[i][j]=dp[i-1][j-1]+1\n",
    "            else:\n",
    "                dp[i][j]=max(dp[i-1][j],dp[i][j-1])\n",
    "    #recunstruct lcs from dp array\n",
    "    lcs=[]\n",
    "    i,j=m,n\n",
    "    while i>0 and j>0:\n",
    "        if s[i-1]==t[j-1]:\n",
    "            lcs.append(s[i-1])\n",
    "            i-=1\n",
    "            j-=1\n",
    "        elif dp[i-1][j]>dp[i][j-1]:\n",
    "            i-=1\n",
    "        else:\n",
    "            j-=1\n",
    "    lcs.reverse()\n",
    "    return \"\".join(lcs)\n",
    "         \n",
    "def main():\n",
    "    sequences=read_fasta(\"lcqs.fasta\")\n",
    "    s=sequences[0]\n",
    "    t=sequences[1]\n",
    "    lcs=longest_common_subseq(s,t)\n",
    "    print(lcs)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDIT\n",
    "Given: Two protein strings s and t in FASTA format (each of length at most 1000 aa).\n",
    "Return: The edit distance dE(s,t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta using biopython function(record refers to header and seq)\n",
    "        sequences.append(str(record.seq))#add sequences of dna to empty list\n",
    "    return sequences#return list of dna sequences\n",
    "def edit_dist(s,t):\n",
    "    m,n=len(s), len(t)\n",
    "    dp=[[0]*(n+1) for _ in range(m+1)]\n",
    "    #to initialize dp\n",
    "    for i in range(m+1):\n",
    "        dp[i][0]=i\n",
    "    for j in range(n+1):\n",
    "        dp[0][j]=j\n",
    "        #fill dp\n",
    "    for i in range(1,m+1):#loop through s\n",
    "        for j in range(1,n+1):#loop thorugh t\n",
    "            if s[i-1]==t[j-1]:#the 2 characters match, we don't have to do nothing \n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "            else:#if the chacaters are fifferent, is because of 3 possible operations, so deletion, inserion and substituition:for any of thse we add 1\n",
    "                dp[i][j]=min(dp[i-1][j]+1,dp[i][j-1]+1,dp[i-1][j-1]+1)\n",
    "    return dp[m][n]\n",
    "def main():\n",
    "    sequences=read_fasta(\"edit.fasta\")\n",
    "    s=sequences[0]\n",
    "    t=sequences[1]\n",
    "    distance=edit_dist(s,t)\n",
    "    print(distance)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDITA\n",
    "Given: Two protein strings s and t in FASTA format (with each string having length at most 1000 aa).\n",
    "Return: The edit distance dE(s,t) followed by two augmented strings s′ and t′ representing an optimal \n",
    "alignment of s and t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "QIMDPMRWGSINQFNQDGAYQQNLWVQRQWTWKFYYTEPQMEVAKIIHANIHHHHFPWQSWLLGFIIQCYDPHRKLSLTMYKDCI---RWERDTIECMSVVRQLRLHDPKAKELIQVPYATLEKLFRKACACNEAIAYILLKAWSYIPECPSMEPHMQPPGILGQDLQDVICRPRGRCNMRAGKPLTIWKLFGIDYDDSRCFCLNWERLEINTNHFGGSSHAHYMVEDQTENGEHFCWGNRAALHYKNGEFGFCM---RSATGY----GSGLCMWPATTMPPQYPYWGVETQGHYTIQPNSRWLRLWWFAY--GYQLAARVYDMHDAAMYTCDYQVPVLKQMIIAVSGFCIS----SIK-IA-FIPVEHAATTFEQVGNSCEDYIFPQLYHVCPGDHTKQFHSKWEDDWYINPFWFEFKENCPIAHANVHNITF--E--WE-RYGRYNMEQYGYVDDMTVVISSLCWRRPDQHNHVG-N------QYHPCEGWNWLMQMKR---AW-----SAVQVSKMLSQKFLLEEDCLCTITVATLDGGWYEASGYCRENFHIFGPSQCGCRMAIIPF-WATSEACDHKATSNDWEPTQLERYWQETVDDPKKKWIPP-DHWYVSQSFVYGNWVVPTSTDAQTHEGKTNIQCNQFRYWIHWHMQHKKFESMQMEKKCVSQSIYEYPVSVYAFEIVIYMNVHFLVNPTPVHTQVWEIYENPYTAMEKRYQCAFAVR-KYGVEDTDTAERTRRAVRAWHVETKMQIEFTMMWPSMSQKPR---F-TWNVFN-ECVSGDVQI-W\n",
      "QKMDPMRWGSINQQNLWVQRHCN-YLKWQWTWKFYYT----EVAKIPHANGTWNPGP-FTWLLGFIIQCYDPHRKESLWMYKTCIMSCTWYRDTIECMSVVR--SLH--KHPQLEKLP--NWRKACNYALAHNEAAAYILLKAWS-IPECPSMEPHM---------RQDVICRPRGMCNMRAGKPLT--K---------KWFCLNWE-LEINTNH----EHSQSFVVWGSWWIWHHKTMSR-HYMVEDQTFGFCMQFHCEATGYATFMGSGLC-HGSETQGHQ--NW---DLG--TIQPNSRWLRVWWFNYEVQYQLAARVY---D--M-TCDYQVPVLKQMIGAVSGFCISAQRVKIKSHAYWCCLDLIIPQLEERGHS--NFVQVACDWVCPGDHT-QFHSKWEDDWYINPFWFEFKENCPIAHANVHNITFDWEVDLELRVGRYDM--TVVISQYNVWDNDLCWRRPDQHNHVGKNDIDHPYMYHPCEGWNWLMQMKRGWGIWHIIPFFAVQVSKMLSQSFLLEED--C----ATLDGGWYEASGY---------WSQCG-ASAIIPFCAATSEACDHKATSND-----LERYWQETVDDPKKKWIPPSFEPWHSWCHWYVLQSFVYSTDLQTHHG-----CNQFRYWIGW---H-----M-NE-PCV--SIYEEPVNPTPRHVWIY---H---IHRPALT-----YENPYTAMEKRYCCFFAVRGDYGVEDTDTAERFARAWRAWHSEGKMQFEFTMMWSSMSQKPRKLYFDGWLTWNDTQIMHPWRIDT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta using biopython function(record refers to header and seq)\n",
    "        sequences.append(str(record.seq))#add sequences of dna to empty list\n",
    "    return sequences#return list of sequences\n",
    "def edit_distance_alignment(s,t):#using dp array we first calculate edit distance\n",
    "    m,n=len(s), len(t)\n",
    "    dp=[[0]*(n+1) for _ in range(m+1)]\n",
    "    #to initialize dp\n",
    "    for i in range(m+1):\n",
    "        dp[i][0]=i\n",
    "    for j in range(n+1):\n",
    "        dp[0][j]=j\n",
    "        #fill dp\n",
    "    for i in range(1,m+1):#loop through s\n",
    "        for j in range(1,n+1):#loop thorugh t\n",
    "            if s[i-1]==t[j-1]:#the 2 characters match, we don't have to do nothing \n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "            else:#if the characters are different, is because of 3 possible operations, so deletion, inserion and substituition:for any of thse we add 1\n",
    "                dp[i][j]=min(dp[i-1][j]+1,dp[i][j-1]+1,dp[i-1][j-1]+1)#backtrack to construct alignment\n",
    "    i,j=m,n#i current position of s during backtracking and j current position of t during backtracking\n",
    "    aligned_s=[]\n",
    "    aligned_t=[]\n",
    "    while i>0 or j>0:\n",
    "        if i>0 and j>0 and dp[i][j]==dp[i-1][j-1]+(0 if s[i-1]==t[j-1] else 1):\n",
    "            aligned_s.append(s[i-1])\n",
    "            aligned_t.append(t[j-1])\n",
    "            i-=1\n",
    "            j-=1\n",
    "        elif i>0 and dp[i][j]==dp[i-1][j]+1:\n",
    "            aligned_s.append(s[i-1])\n",
    "            aligned_t.append('-')\n",
    "            i-=1\n",
    "        else:\n",
    "            aligned_s.append('-')\n",
    "            aligned_t.append(t[j-1])\n",
    "            j-=1\n",
    "    aligned_s=''.join(reversed(aligned_s))#we backtrack in dynamic programming so both are reversed\n",
    "    aligned_t=''.join(reversed(aligned_t))\n",
    "    return dp[m][n], aligned_s, aligned_t\n",
    "\n",
    "def main():\n",
    "    s,t=read_fasta(\"edta.fasta\")\n",
    "    edit_dist, aligned_s, aligned_t=edit_distance_alignment(s,t)\n",
    "    print(edit_dist)\n",
    "    print(aligned_s)\n",
    "    print(aligned_t)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTEA\n",
    "Given: Two protein strings s and t in FASTA format, each of length at most 1000 aa.\n",
    "Return: The total number of optimal alignments of s and t with respect to edit alignment score, modulo 134,217,727 (227-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133328419\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "MOD=134217727\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta using biopython function(record refers to header and seq)\n",
    "        sequences.append(str(record.seq))#add sequences of dna to empty list\n",
    "    return sequences#return list of sequences\n",
    "\n",
    "def edit_dist_count(s,t):#using dp array we first calculate edit distance and count to number the optimal alignments\n",
    "    m,n=len(s), len(t)\n",
    "    dp=[[0]*(n+1) for _ in range(m+1)]\n",
    "    count=[[0]*(n+1) for _ in range(m+1)]\n",
    "    #to initialize dp\n",
    "    for i in range(m+1):\n",
    "        dp[i][0]=i\n",
    "        count[i][0]=1\n",
    "    for j in range(n+1):\n",
    "        dp[0][j]=j\n",
    "        count[j][0]=1\n",
    "    for i in range(1,m+1):#loop through s\n",
    "        for j in range(1,n+1):#loop thorugh t\n",
    "            if s[i-1]==t[j-1]:#the 2 characters match, we don't have to do nothing \n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "                count[i][j]=count[i-1][j-1]\n",
    "            else:#if the characters are different, is because of 3 possible operations, so deletion, inserion and substituition:for any of thse we add 1\n",
    "                dp[i][j]=min(dp[i-1][j]+1,dp[i][j-1]+1,dp[i-1][j-1]+1)#backtrack to construct alignment\n",
    "            if dp[i][j]==dp[i-1][j]+1:\n",
    "                count [i][j]+=count[i-1][j]\n",
    "            if dp[i][j]==dp[i][j-1]+1:\n",
    "                count [i][j]+=count[i][j-1]\n",
    "            if dp[i][j]==dp[i-1][j-1]+1:\n",
    "                count [i][j]+=count[i-1][j-1]\n",
    "            count[i][j]%=MOD\n",
    "    return dp[m][n], count[m][n]\n",
    "def main():\n",
    "    sequences=read_fasta(\"ctea.fasta\")\n",
    "    s,t=sequences[0],sequences[1]\n",
    "    edit_dist, aligned_count=edit_dist_count(s,t)\n",
    "    print(aligned_count)\n",
    "   \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLOB\n",
    "Given: Two protein strings s and t in FASTA format (each of length at most 1000 aa).\n",
    "Return: The maximum alignment score between s and t. Use:\n",
    "The BLOSUM62 scoring matrix.\n",
    "Linear gap penalty equal to 5 (i.e., a cost of -5 is assessed for each gap symbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "blos_score_matrix= [\n",
    "    [4, 0, -2, -1, -2, 0, -2, -1, -1, -1, -1, -2, -1, -1, -1, 1, 0, 0, -3, -2],\n",
    "    [0, 9, -3, -4, -2, -3, -3, -1, -3, -1, -1, -3, -3, -3, -3, -1, -1, -1, -2, -2],\n",
    "    [-2, -3, 6, 2, -3, -1, -1, -3, -1, -4, -3, 1, -1, 0, -2, 0, -1, -3, -4, -3],\n",
    "    [-1, -4, 2, 5, -3, -2, 0, -3, 1, -3, -2, 0, -1, 2, 0, 0, -1, -2, -3, -2],\n",
    "    [-2, -2, -3, -3, 6, -3, -1, 0, -3, 0, 0, -3, -4, -3, -3, -2, -2, -1, 1, 3],\n",
    "    [0, -3, -1, -2, -3, 6, -2, -4, -2, -4, -3, 0, -2, -2, -2, 0, -2, -3, -2, -3],\n",
    "    [-2, -3, -1, 0, -1, -2, 8, -3, -1, -3, -2, 1, -2, 0, 0, -1, -2, -3, -2, 2],\n",
    "    [-1, -1, -3, -3, 0, -4, -3, 4, -3, 2, 1, -3, -3, -3, -3, -2, -1, 3, -3, -1],\n",
    "    [-1, -3, -1, 1, -3, -2, -1, -3, 5, -2, -1, 0, -1, 1, 2, 0, -1, -2, -3, -2],\n",
    "    [-1, -1, -4, -3, 0, -4, -3, 2, -2, 4, 2, -3, -3, -2, -2, -2, -1, 1, -2, -1],\n",
    "    [-1, -1, -3, -2, 0, -3, -2, 1, -1, 2, 5, -2, -2, 0, -1, -1, -1, 1, -1, -1],\n",
    "    [-2, -3, 1, 0, -3, 0, 1, -3, 0, -3, -2, 6, -2, 0, 0, 1, 0, -3, -4, -2],\n",
    "    [-1, -3, -1, -1, -4, -2, -2, -3, -1, -3, -2, -2, 7, -1, -2, -1, -1, -2, -4, -3],\n",
    "    [-1, -3, 0, 2, -3, -2, 0, -3, 1, -2, 0, 0, -1, 5, 1, 0, -1, -2, -2, -1],\n",
    "    [-1, -3, -2, 0, -3, -2, 0, -3, 2, -2, -1, 0, -2, 1, 5, -1, -1, -3, -3, -2],\n",
    "    [1, -1, 0, 0, -2, 0, -1, -2, 0, -2, -1, 1, -1, 0, -1, 4, 1, -2, -3, -2],\n",
    "    [0, -1, -1, -1, -2, -2, -2, -1, -1, -1, -1, 0, -1, -1, -1, 1, 5, 0, -2, -2],\n",
    "    [0, -1, -3, -2, -1, -3, -3, 3, -2, 1, 1, -3, -2, -2, -3, -2, 0, 4, -3, -1],\n",
    "    [-3, -2, -4, -3, 1, -2, -2, -3, -3, -2, -1, -4, -4, -2, -3, -3, -2, -3, 11, 2],\n",
    "    [-2, -2, -3, -2, 3, -3, 2, -1, -2, -1, -1, -2, -3, -1, -2, -2, -2, -1, 2, 7]\n",
    "]\n",
    "\n",
    "gap_penalty=-5\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):#parse fasta using biopython function(record refers to header and seq)\n",
    "        sequences.append(str(record.seq))#add sequences of dna to empty list\n",
    "    return sequences#return list of sequences\n",
    "\n",
    "#map aminoacids to their indices in the score matrix\n",
    "amino_a=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "amino_a_index={aa:idx for idx, aa in enumerate(amino_a)}\n",
    "\n",
    "def get_score(a,b):#returns score for aligning characters 'a'and 'b'based on blosum matrix\n",
    "    return blos_score_matrix[amino_a_index[a]][amino_a_index[b]]\n",
    "    \n",
    "def max_alignment_score(s,t):#compute max alignment between s and t, starting from blosum and including gap penalty\n",
    "    m,n=len(s), len(t)\n",
    "    dp=[[0]*(n+1) for _ in range(m+1)]\n",
    "    #to initialize dp\n",
    "    for i in range(1, m+1):\n",
    "        dp[i][0]=dp[i-1][0]+ gap_penalty\n",
    "    for j in range(1, n+1):\n",
    "        dp[0][j]=dp[0][j-1] + gap_penalty\n",
    "        #fill dp\n",
    "    for i in range(1,m+1):#loop through s\n",
    "        for j in range(1,n+1):#loop thorugh t\n",
    "            match=dp[i-1][j-1]+ get_score(s[i-1],t[j-1])#match/mismatch\n",
    "            delete=dp[i-1][j]+gap_penalty#deletion\n",
    "            insert=dp[i][j-1]+gap_penalty #insertion\n",
    "            dp[i][j]=max(match,delete,insert)#this  time we take the maximum score\n",
    "    return dp[m][n]\n",
    "\n",
    "def main():\n",
    "    sequences=read_fasta(\"glob.fasta\")\n",
    "    s,t=sequences[0], sequences[1]\n",
    "    score=max_alignment_score(s,t)\n",
    "    print(score)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"name\":\"Alice\", \"average_score\":93.75},\n",
      "{\"name\":\"Charlie\", \"average_score\":95.0},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "students_with_averages = list(map(lambda student: {\n",
    "    \"name\": student[\"name\"],\n",
    "    \"average_score\": reduce(lambda x, y: x + y, student[\"scores\"]) / len(student[\"scores\"])\n",
    "}, students))\n",
    "\n",
    "top_students = list(filter(lambda student: student[\"average_score\"] > 90, students_with_averages))\n",
    "\n",
    "print(\"[\")\n",
    "for student in top_students:\n",
    "    print(f'{{\"name\":\"{student[\"name\"]}\", \"average_score\":{student[\"average_score\"]}}},')\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [64, 89, 97, 65]},\n",
       " {'name': 'Student 2', 'scores': [86, 72, 67, 67, 88, 71]},\n",
       " {'name': 'Student 3', 'scores': [83, 96, 97, 74, 92, 62]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test#\n",
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"name\":\"Student 48\", \"average_score\":90.33333333333333},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "from functools import reduce\n",
    "students_with_averages = list(map(lambda student: {\n",
    "    \"name\": student[\"name\"],\n",
    "    \"average_score\": reduce(lambda x, y: x + y, student[\"scores\"]) / len(student[\"scores\"])\n",
    "}, random_student_dataset))\n",
    "\n",
    "top_students = list(filter(lambda student: student[\"average_score\"] > 90, students_with_averages))\n",
    "\n",
    "print(\"[\")\n",
    "for student in top_students[:3]:\n",
    "    print(f'{{\"name\":\"{student[\"name\"]}\", \"average_score\":{student[\"average_score\"]}}},')\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"category\":\"Sports\", \"average_price\":90.0},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# your code goes here\n",
    "from functools import reduce\n",
    "categories={}\n",
    "for product in products:\n",
    "    if product[\"category\"] in categories:\n",
    "        categories[product[\"category\"]].append(product[\"price\"])\n",
    "    else:\n",
    "        categories[product[\"category\"]]=[product[\"price\"]]\n",
    "prods_averages = list(map(lambda category: {\n",
    "    \"category\": category,\n",
    "    \"average_price\": reduce(lambda x, y: x + y, categories[category]) / len(categories[category])\n",
    "}, categories))\n",
    "\n",
    "filtered_products = list(filter(lambda product: product[\"average_price\"] > 50, prods_averages))\n",
    "\n",
    "print(\"[\")\n",
    "for product in filtered_products:\n",
    "    print(f'{{\"category\":\"{product[\"category\"]}\", \"average_price\":{product[\"average_price\"]}}},')\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 127, 'category': 'Electronics'},\n",
       " {'name': 'Product 2', 'price': 99, 'category': 'Toys'},\n",
       " {'name': 'Product 3', 'price': 137, 'category': 'Sports'},\n",
       " {'name': 'Product 4', 'price': 178, 'category': 'Home'},\n",
       " {'name': 'Product 5', 'price': 159, 'category': 'Books'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"category\":\"Electronics\", \"average_price\":115.36363636363636},\n",
      "{\"category\":\"Toys\", \"average_price\":93.9090909090909},\n",
      "{\"category\":\"Sports\", \"average_price\":106.0},\n",
      "{\"category\":\"Home\", \"average_price\":78.93333333333334},\n",
      "{\"category\":\"Books\", \"average_price\":104.6470588235294},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "from functools import reduce\n",
    "# Step 1: Calculate average price using map\n",
    "categories={}\n",
    "for product in random_dataset:\n",
    "    if product[\"category\"] in categories:\n",
    "        categories[product[\"category\"]].append(product[\"price\"])\n",
    "    else:\n",
    "        categories[product[\"category\"]]=[product[\"price\"]]\n",
    "prods_averages = list(map(lambda category: {\n",
    "    \"category\": category,\n",
    "    \"average_price\": reduce(lambda x, y: x + y, categories[category]) / len(categories[category])\n",
    "}, categories))\n",
    "\n",
    "# Step 2: Filter prices with average  above 50\n",
    "filtered_products = list(filter(lambda product: product[\"average_price\"] > 50, prods_averages))\n",
    "\n",
    "# Output\n",
    "print(\"[\")\n",
    "for product in filtered_products[:5]:\n",
    "    print(f'{{\"category\":\"{product[\"category\"]}\", \"average_price\":{product[\"average_price\"]}}},')\n",
    "print(\"]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 3#\n",
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"department\":\"Engineering\", \"average_salary\":72500.0},\n",
      "{\"department\":\"Marketing\", \"average_salary\":70000.0},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "# Step 1: Calculate average price using map\n",
    "departments={}\n",
    "for department in employees:\n",
    "    if department [\"department\"] in departments:\n",
    "        departments[department[\"department\"]].append(department[\"salary\"])\n",
    "    else:\n",
    "        departments[department[\"department\"]]=[department[\"salary\"]]\n",
    "salary_averages = list(map(lambda department: {\n",
    "    \"department\": department,\n",
    "    \"average_salary\": reduce(lambda x, y: x + y, departments[department]) / len(departments[department])\n",
    "}, departments))\n",
    "\n",
    "# Step 2: Filter prices with average  above 50\n",
    "filtered_salary = list(filter(lambda employe: employe[\"average_salary\"] > 65000, salary_averages))\n",
    "\n",
    "# Output\n",
    "print(\"[\")\n",
    "for employe in filtered_salary:\n",
    "    print(f'{{\"department\":\"{employe[\"department\"]}\", \"average_salary\":{employe[\"average_salary\"]}}},')\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 45641, 'department': 'Sales'},\n",
       " {'name': 'Employee 2', 'salary': 119276, 'department': 'Sales'},\n",
       " {'name': 'Employee 3', 'salary': 67910, 'department': 'Marketing'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"department\":\"Sales\", \"average_salary\":81745.46153846153},\n",
      "{\"department\":\"Marketing\", \"average_salary\":87416.2},\n",
      "{\"department\":\"Finance\", \"average_salary\":80614.16666666667},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "from functools import reduce\n",
    "# Step 1: Calculate average price using map\n",
    "departments={}\n",
    "for department in random_employee_dataset:\n",
    "    if department [\"department\"] in departments:\n",
    "        departments[department[\"department\"]].append(department[\"salary\"])\n",
    "    else:\n",
    "        departments[department[\"department\"]]=[department[\"salary\"]]\n",
    "salary_averages = list(map(lambda department: {\n",
    "    \"department\": department,\n",
    "    \"average_salary\": reduce(lambda x, y: x + y, departments[department]) / len(departments[department])\n",
    "}, departments))\n",
    "\n",
    "# Step 2: Filter prices with average  above 50\n",
    "filtered_salary = list(filter(lambda employe: employe[\"average_salary\"] > 65000, salary_averages))\n",
    "\n",
    "# Output\n",
    "print(\"[\")\n",
    "for employe in filtered_salary[:3]:\n",
    "    print(f'{{\"department\":\"{employe[\"department\"]}\", \"average_salary\":{employe[\"average_salary\"]}}},')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\biopython-1.85.dev0-py3.13-win-amd64.egg\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#functions biopython using pairwise2#\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMatches(s1,s2):\n",
    "    alignments=pairwise2.align.globalxx(s1,s2, one_alignment_only=True)\n",
    "    aligned_s1, aligned_s2,_,_, _=alignments[0]\n",
    "    matches=sum(1 for a, b in zip(aligned_s1, aligned_s2)if a==b)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMismatches(s1,s2):\n",
    "    alignments=pairwise2.align.globalxx(s1,s2, one_alignment_only=True)\n",
    "    aligned_s1, aligned_s2,_,_, _=alignments[0]\n",
    "    mismatches=sum(1 for a, b in zip(aligned_s1, aligned_s2)if a!=b and a!='-'and b!='-')\n",
    "    return mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGapOpens(s1,s2):\n",
    "    alignments=pairwise2.align.globalxx(s1,s2, one_alignment_only=True)\n",
    "    aligned_s1, aligned_s2,_,_, _=alignments[0]\n",
    "    gap_opens=0\n",
    "    gap_o_s1=False\n",
    "    gap_o_s2=False\n",
    "    for a,b in zip(aligned_s1, aligned_s2):#check for gaps in s1 and s2\n",
    "        if a =='-' and not gap_o_s1:\n",
    "            gap_opens+=1\n",
    "            gap_o_s1=True#a gap is found\n",
    "        elif a !='-':\n",
    "            gap_o_s1=False#reset gap traxker because no gap is found\n",
    "        if b =='-' and not gap_o_s2:\n",
    "            gap_opens+=1\n",
    "            gap_o_s2=True#a gap is found\n",
    "        elif b !='-':\n",
    "            gap_o_s2=False#reset gap traxker because no gap is found\n",
    "    return gap_opens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGapExtensions(s1,s2):\n",
    "    alignments=pairwise2.align.globalxx(s1,s2, one_alignment_only=True)\n",
    "    aligned_s1, aligned_s2,_,_, _=alignments[0]\n",
    "    gap_extension=0\n",
    "    gap_o_s1=False\n",
    "    gap_o_s2=False\n",
    "    for a,b in zip(aligned_s1, aligned_s2):#check for gaps in s1 and s2\n",
    "        if a =='-':#so if gap exists\n",
    "            if gap_o_s1:#the gap is open, so it's an extension \n",
    "                gap_extension+=1\n",
    "            gap_o_s1=True#keep gap open\n",
    "        else:\n",
    "            gap_o_s1=False#reset when no gap\n",
    "        if b =='-':#so if gap exists\n",
    "            if gap_o_s2:#the gap is open, so it's an extension \n",
    "                gap_extension+=1\n",
    "            gap_o_s2=True#keep gap open\n",
    "        else:\n",
    "            gap_o_s2=False#reset when no gap\n",
    "    return gap_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    alignments=pairwise2.align.globalms(\n",
    "        s1,s2,\n",
    "        matchScore,\n",
    "        mismatchPenalty,\n",
    "        gapOpenPenalty, \n",
    "        gapExtensionPenalty,\n",
    "        one_alignment_only=True \n",
    "    )\n",
    "    alignment_score=alignments[0].score\n",
    "    return alignment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment score: 3.3999999999999844\n",
      "custom alignment score: 3.3999999999999844\n",
      "matches: 103\n",
      "mismatches: 0\n",
      "gap opens: 117\n",
      "gap extensions: 224\n"
     ]
    }
   ],
   "source": [
    "#test#\n",
    "#for test\n",
    "from Bio import SeqIO\n",
    "def read_fasta(filename):\n",
    "    sequences=[]\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):\n",
    "        sequences.append(str(record.seq))\n",
    "    return sequences\n",
    "s1=read_fasta(\"IL12A (1).fasta\")[0]\n",
    "s2=read_fasta(\"IL12B.fasta\")[0]\n",
    "alignments=pairwise2.align.globalms(s1,s2,1,-1,-0.5,-0.2, one_alignment_only=True)\n",
    "aligned_s1, aligned_s2, score, start, end=alignments[0]\n",
    "print(\"alignment score:\", score)\n",
    "custom_score=getScore(s1,s2,1,-1,-0.5,-0.2)\n",
    "print(\"custom alignment score:\", custom_score)\n",
    "matches=countMatches(s1,s2)\n",
    "mismatches=countMismatches(s1,s2)\n",
    "gap_opens=countGapOpens(s1,s2)\n",
    "gap_extensions=countGapExtensions(s1,s2)\n",
    "print(\"matches:\",matches)\n",
    "print(\"mismatches:\", mismatches)\n",
    "print(\"gap opens:\", gap_opens)\n",
    "print(\"gap extensions:\", gap_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output of the test here\n",
    "'''alignment score: 3.3999999999999844\n",
    "custom alignment score: 3.3999999999999844\n",
    "matches: 103\n",
    "mismatches: 0\n",
    "gap opens: 117\n",
    "gap extensions: 224'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
